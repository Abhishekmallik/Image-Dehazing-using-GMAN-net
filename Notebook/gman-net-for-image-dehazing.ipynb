{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":false},"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport glob\nimport random\nfrom PIL import Image\nimport time\nimport datetime\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import mean_squared_error\nfrom tensorflow.keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing and loading of data"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# function to load the image in the form of tensors.\n\ndef load_image(img_path):\n    img = tf.io.read_file(img_path)\n    img = tf.io.decode_jpeg(img, channels = 3)\n    img = tf.image.resize(img, size = (412, 548), antialias = True)\n    img = img / 255.0\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# function to get the path of individual image.\n\ndef data_path(orig_img_path, hazy_img_path):\n    \n    train_img = []\n    val_img = []\n    \n    orig_img = glob.glob(orig_img_path + '/*.jpg')\n    n = len(orig_img)\n    random.shuffle(orig_img)\n    train_keys = orig_img[:int(0.9*n)]        #90% data for train, 10% for test\n    val_keys = orig_img[int(0.9*n):]\n    \n    split_dict = {}\n    for key in train_keys:\n        split_dict[key] = 'train'\n    for key in val_keys:\n        split_dict[key] = 'val'\n        \n    hazy_img = glob.glob(hazy_img_path + '/*.jpg')\n    for img in hazy_img:\n        img_name = img.split('/')[-1]\n        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.jpg'\n        if (split_dict[orig_path] == 'train'):\n            train_img.append([img, orig_path])\n        else:\n            val_img.append([img, orig_path])\n            \n    return train_img, val_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# function to load tensor image data in batches.\n\ndef dataloader(train_data, val_data, batch_size):\n    \n    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))\n    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))\n    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n    \n    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))\n    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))\n    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n    \n    return train, val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# function to display output.\n\ndef display_img(model, hazy_img, orig_img):\n    \n    dehazed_img = model(hazy_img, training = True)\n    plt.figure(figsize = (15,15))\n    \n    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]\n    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']\n    \n    for i in range(3):\n        plt.subplot(1, 3, i+1)\n        plt.title(title[i])\n        plt.imshow(display_list[i])\n        plt.axis('off')\n        \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Network Function"},{"metadata":{"trusted":true,"scrolled":false,"_kg_hide-input":true},"cell_type":"code","source":"def gman_net():\n    \n    inputs = tf.keras.Input(shape = [412, 548, 3])     # height, width of input image changed because of error in output\n    \n                                    ######################## GMAN Network ###########################\n        \n    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                  bias_initializer = b_init, kernel_regularizer = regularizer)(inputs)\n    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n    \n    \n                                    #### Encoding Layers #####\n    conv_up = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n    conv_up = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv_up)\n                                    \n                                    #### Residual Layers #####\n    conv1_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                   bias_initializer = b_init, kernel_regularizer = regularizer)(conv_up)\n    conv1_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv1_1)\n    conv1_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n                   bias_initializer = b_init, kernel_regularizer = regularizer)(conv1_2)\n    conc1 = tf.add(conv1_3, conv1_1)\n    conv1 = tf.keras.activations.relu(conc1)\n\n    conv2_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv1)\n    conv2_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2_1)\n    conv2_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2_2)\n    conc2 = tf.add(conv2_3, conv2_1)\n    conv2 = tf.keras.activations.relu(conc2)\n\n    conv3_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2)\n    conv3_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_1)\n    conv3_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_2)\n    conv3_4 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_3)\n    conv3_5 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_4)\n    conc3 = tf.add(conv3_5, conv3_1)\n    conv3 = tf.keras.activations.relu(conc3)\n\n    conv4_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3)\n    conv4_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_1)\n    conv4_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_2)\n    conv4_4 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_3)\n    conv4_5 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_4)\n    conc4 = tf.add(conv4_5, conv4_1)\n    conv4 = tf.keras.activations.relu(conc4)\n\n                                            ##### Decoding Layers #####\n    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n                             kernel_regularizer = regularizer)(conv4)\n    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n                             kernel_regularizer = regularizer)(deconv)\n\n    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                  bias_initializer = b_init, kernel_regularizer = regularizer)(deconv)\n    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n    conc = tf.add(conv, inputs)\n    gman_output = tf.keras.activations.relu(conc)\n    \n                               ######################## Parallel Network ###########################\n    \n    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 4, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                 kernel_regularizer = regularizer)(inputs)\n    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                 kernel_regularizer = regularizer)(conv)\n    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                 kernel_regularizer = regularizer)(conv)\n    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                 kernel_regularizer = regularizer)(conv)\n    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                 kernel_regularizer = regularizer)(conv)\n    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n                 kernel_regularizer = regularizer)(conv)\n    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, dilation_rate = 4, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n                           activation = 'relu', kernel_regularizer = regularizer)(conv)\n    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n                 kernel_regularizer = regularizer)(deconv)\n    conc = tf.add(conv, inputs)\n    pn_output = tf.keras.activations.relu(conc)\n    \n    output = tf.add(gman_output, pn_output)\n    \n    return Model(inputs = inputs, outputs = output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Hyperparameters\nepochs = 10\nbatch_size = 8\nk_init = tf.keras.initializers.random_normal(stddev=0.008, seed = 101)      \nregularizer = tf.keras.regularizers.L2(1e-4)\nb_init = tf.constant_initializer()\n\ntrain_data, val_data = data_path(orig_img_path = '../input/dehaze/clear_images', hazy_img_path = '../input/dehaze/haze')\ntrain, val = dataloader(train_data, val_data, batch_size)\n\noptimizer = Adam(learning_rate = 1e-4)\nnet = gman_net()\n\ntrain_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"train loss\")\nval_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"val loss\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_kg_hide-output":true},"cell_type":"code","source":"def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):\n    \n    for epoch in range(epochs):\n        \n        print(\"\\nStart of epoch %d\" % (epoch,), end=' ')\n        start_time_epoch = time.time()\n        start_time_step = time.time()\n        \n        # training loop\n        \n        for step, (train_batch_haze, train_batch_orig) in enumerate(train):\n\n            with tf.GradientTape() as tape:\n\n                train_logits = net(train_batch_haze, training = True)\n                loss = mean_squared_error(train_batch_orig, train_logits)\n\n            grads = tape.gradient(loss, net.trainable_weights)\n            optimizer.apply_gradients(zip(grads, net.trainable_weights))\n\n            train_loss_tracker.update_state(train_batch_orig, train_logits)\n            if step == 0:\n                print('[', end='')\n            if step % 64 == 0:\n                print('=', end='')\n        \n        print(']', end='')\n        print('  -  ', end='')\n        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')\n        \n        # validation loop\n        \n        for step, (val_batch_haze, val_batch_orig) in enumerate(val):\n            val_logits = net(val_batch_haze, training = False)\n            val_loss_tracker.update_state(val_batch_orig, val_logits)\n            \n            if step % 32 ==0:\n                display_img(net, val_batch_haze, val_batch_orig)\n        \n        print('  -  ', end='')\n        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')\n        print('  -  ', end=' ')\n        print(\"Time taken: %.2fs\" % (time.time() - start_time_epoch))\n        \n        net.save('trained_model')           # save the model(variables, weights, etc)\n        train_loss_tracker.reset_states()\n        val_loss_tracker.reset_states()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"%%time\ntrain_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def evaluate(net, test_img_path):\n    \n    test_img = glob.glob(test_img_path + '/*.jpg')\n    random.shuffle(test_img)\n    \n    for img in test_img:\n        \n        img = tf.io.read_file(img)\n        img = tf.io.decode_jpeg(img, channels = 3)\n        \n        if img.shape[1] > img.shape[0]:\n            img = tf.image.resize(img, size = (1080, 1920), antialias = True)\n        if img.shape[1] < img.shape[0]:\n            img = tf.image.resize(img, size = (1920, 1080), antialias = True)\n        \n        img = img / 255.0\n        img = tf.expand_dims(img, axis = 0)      #transform input image from 3D to 4D###\n        \n        dehaze = net(img, training = False)\n        \n        plt.figure(figsize = (80, 80))\n        \n        display_list = [img[0], dehaze[0]]       #make the first dimension zero\n        title = ['Hazy Image', 'Dehazed Image']\n\n        for i in range(2):\n            plt.subplot(1, 2, i+1)\n            plt.title(title[i], fontsize = 65, y = 1.045)\n            plt.imshow(display_list[i])\n            plt.axis('off')\n        \n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_kg_hide-output":true},"cell_type":"code","source":"test_net = tf.keras.models.load_model('trained_model', compile = False)\nevaluate(test_net, '../input/hazy-test-images')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}